#!/usr/bin/env python3
import os
import sys
import rclpy
from rclpy.node import Node
from rclpy.logging import get_logger
from geometry_msgs.msg import TransformStamped
from std_msgs.msg import String
import time

import numpy as np
import tf2_ros
import tf_transformations
# from time import time

from std_msgs.msg import Header
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge,CvBridgeError

import cv2
from ultralytics import YOLO
from ament_index_python.packages import get_package_share_directory

class YoloDetection(Node):
# åˆå§‹åŒ–å‡½æ•°ï¼ŒåŒ…æ‹¬åŠ è½½æ¨¡å‹å’Œåˆ›å»ºè®¢é˜…è€…
    def __init__(self):
        # åˆå§‹åŒ–èŠ‚ç‚¹
        super().__init__('Yolo')
        self.logger = get_logger("yolov8") # åˆ›å»ºæ—¥å¿—è®°å½•å™¨

        # åˆå§‹åŒ–æ¨¡å‹ä¿¡æ¯
        ros2_yolov8 = get_package_share_directory('ros2_yolov8')  # åŠŸèƒ½åŒ…åœ°å€
        model_path  = os.path.join(ros2_yolov8, 'config', 'fruits-obb.pt')  # æ°´æœè¯†åˆ«æ¨¡å‹è·¯å¾„
        self.model  = YOLO(model_path) # åŠ è½½æ¨¡å‹
        self.device = 'cpu'           # ä½¿ç”¨cpuè¿›è¡Œæ¨ç†
        self.conf   = 0.5               # è®¾ç½®æ¨¡å‹ç½®ä¿¡åº¦      

        # åˆå§‹åŒ–ç›¸æœºä¿¡æ¯
        self.sub_info  = self.create_subscription(CameraInfo, '/camera/camera/color/camera_info', self.imageCameraInfoCallback, 10)    # ç›¸æœºä¿¡æ¯è¯é¢˜
        self.image_sub = self.create_subscription(Image, '/camera/camera/color/image_raw', self.detect, 10)                           # RGBå›¾åƒè¯é¢˜
        time.sleep(3)                         # ä¼‘çœ 3ç§’
        self.depth_sub = self.create_subscription(Image, "/camera/camera/aligned_depth_to_color/image_raw", self.camera_depth_cb, 10) # æ·±åº¦å›¾åƒè¯é¢˜
        self.debug_pub = self.create_publisher(Image, "/debug_image", 1)      # æœ€ç»ˆå›¾åƒè¾“å‡ºè¯é¢˜
        self.obj_pub   = self.create_publisher(String, "/object_id", 10)      # æ°´æœIDè¯é¢˜
        self.camera_reference_frame = "camera_link"        # å®šä¹‰æ‘„åƒå¤´åæ ‡ç³»
        self.tf_pub = tf2_ros.TransformBroadcaster(self)   # ç‰©ä½“åæ ‡å˜æ¢å¹¿æ’­
        self.bridge = CvBridge()
        self.obj_id = [1,2,3,4]

        

    def imageCameraInfoCallback(self, msg):
        """
        è·å–ç›¸æœºå†…å‚ä¿¡æ¯
        """
        # è·å–å›¾åƒå°ºå¯¸
        self.image_width  = msg.width
        self.image_height = msg.height
        # è·å–ç›¸æœºå†…å‚
        self.fx = msg.k[0]
        self.fy = msg.k[4]
        self.cx = msg.k[2]
        self.cy = msg.k[5]

    def predict(self, frame):
        '''
        ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        '''
        results = self.model(frame, conf=self.conf,show_labels=False,show_conf=False,show_boxes=False)
        for result in results:    
            self.obb = result.obb
        return results

    def plot_boxes(self, results, frame):
        '''
        è®¡ç®—å¸§ç‡å’Œç»˜åˆ¶è¾¹ç•Œæ¡†
        '''
        fps = 1000.0/ results[0].speed['inference']
        cv2.putText(frame, f'FPS: {int(fps)}', (20,50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)
        frame = results[0].plot()
        return frame

    def detect(self, msg):
        '''
        è®¢é˜…åˆ°RGBå›¾åƒåè¿›è¡Œæ£€æµ‹
        '''
        self.color_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        results    = self.predict(self.color_image)             # yolov8æ£€æµ‹
        frame      = self.plot_boxes(results, self.color_image) # ç»˜åˆ¶è¾¹ç•Œæ¡†
        detect_img = self.bridge.cv2_to_imgmsg(frame, "bgr8")   # å°†OpenCVæ ¼å¼çš„å›¾åƒè½¬æ¢ä¸ºROSæ¶ˆæ¯
        self.debug_pub.publish(detect_img)                      # å‘å¸ƒæ£€æµ‹å›¾åƒ

    # æ·±åº¦å›¾åƒå›è°ƒå‡½æ•°
    def camera_depth_cb(self, msg):
        '''
        è®¢é˜…åˆ°æ·±åº¦å›¾åƒåï¼Œç»“åˆé¢„æµ‹ç»“æœï¼Œç”Ÿæˆç‰©ä½“TFåæ ‡
        '''
        # 1. æ·±åº¦å›¾åƒä¸RGBå›¾åƒèåˆ
        self.depth_image = self.bridge.imgmsg_to_cv2(msg, "32FC1")     # å°†ROSæ¶ˆæ¯è½¬æ¢ä¸ºOpenCVæ ¼å¼çš„æ·±åº¦å›¾åƒ
        depth_array = np.array(self.depth_image, dtype=np.float32)     # å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸ºNumPyæ•°ç»„
        cv2.normalize(depth_array, depth_array, 0, 1, cv2.NORM_MINMAX) # å°†æ·±åº¦å›¾åƒæ•°æ®å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        depth_8 = (depth_array * 255).round().astype(np.uint8)         # å°†å½’ä¸€åŒ–åçš„æ·±åº¦å›¾åƒè½¬æ¢ä¸º8ä½æ— ç¬¦å·æ•´æ•°
        cv_depth = np.zeros_like(self.color_image)                     # åˆ›å»ºä¸RGBå›¾åƒç›¸åŒå¤§å°çš„æ·±åº¦å›¾åƒ
        try:
            cv_depth[:, :, 0] = depth_8                                # å°†æ·±åº¦å›¾åƒæ•°æ®å¤åˆ¶åˆ°RGBå›¾åƒçš„æ¯ä¸ªé€šé“
            cv_depth[:, :, 1] = depth_8
            cv_depth[:, :, 2] = depth_8
        except:
            return   
         
        if len(self.obb) == None: # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç‰©ä½“åˆ™é€€å‡º
            return
        
        # 2. æ ¹æ®è¯†åˆ«åˆ°çš„æ•°é‡è¿›è¡Œéå†ï¼Œæå–ç›®æ ‡ä½ç½®ä¿¡æ¯
        size = self.obb.cls.size(0)       
        for i in range(size): # éå†æ‰€æœ‰çš„ç‰©ä½“
            
            # 3. è·å–ç‰©ä½“çš„è¾¹ç•Œæ¡†åæ ‡
            m_x = int(self.obb.xywhr[i,0])
            m_y = int(self.obb.xywhr[i,1])
            m_w = int(self.obb.xywhr[i,2])
            m_h = int(self.obb.xywhr[i,3])
            m_r = self.obb.xywhr[i,4]
            ip  = int(self.obb.cls[i])
        
            # 4. è·å–çŸ©å½¢ROIåŒºåŸŸ
            obb_xyxyxyxy = self.obb.xyxyxyxy[0]                # å–å‡ºç¬¬ä¸€ä¸ªç›®æ ‡çš„ 8 ä¸ªåæ ‡å€¼      
            points = np.array(obb_xyxyxyxy.view(4, 2).numpy(), dtype=np.int32) # é‡æ–°æ•´ç†æˆ [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]
            left_top_x , left_top_y  = np.min(points, axis=0)  # å·¦ä¸Šè§’
            right_low_x, right_low_y = np.max(points, axis=0)  # å³ä¸‹è§’
            roi_depth = self.depth_image[left_top_y:right_low_y,left_top_x:right_low_x] # è·å–ROIåŒºåŸŸçš„æ·±åº¦å›¾åƒ
            count = 0                                          # åˆå§‹åŒ–ç»Ÿè®¡æ·±åº¦æ¬¡æ•°
            sum_z = 0.0                                        # åˆå§‹åŒ–æ·±åº¦å€¼æ€»å’Œ
            
            # 5. è®¡ç®—ROIåŒºåŸŸå†…æœ‰æ•ˆåƒç´ ç‚¹æ•°é‡ã€æ·±åº¦å€¼æ€»å’Œå’Œå¹³å‡å€¼
            for j in range(0, roi_depth.shape[0]):
                for k in range(0, roi_depth.shape[1]):
                    value = roi_depth.item(j, k) / 1000.0
                    if value > 0:
                        count += 1
                        sum_z += value
            if count == 0 or sum_z == 0:
                return 
            mean_z = sum_z / count # è®¡ç®—ROIåŒºåŸŸå†…å¹³å‡æ·±åº¦å€¼
            # self.get_logger().info(f"ğŸ¯ æ·±åº¦å€¼ä¸º: {mean_z}")
        
            # 6. è®¡ç®—ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ä¸‰ç»´åæ ‡
            x = (m_x - self.cx) / self.fx
            y = (m_y - self.cy) / self.fy
            point_x = mean_z * x
            point_y = mean_z * y
            point_z = mean_z

            # 7.åˆ›å»ºTFå˜æ¢æ¶ˆæ¯å¹¶å‘å¸ƒ
            cube_tf = TransformStamped()
            cube_tf.header.stamp = self.get_clock().now().to_msg()
            cube_tf.header.frame_id = self.camera_reference_frame
            cube_tf.child_frame_id = "object_"+str(ip)
            cube_tf.transform.translation.x = float(point_z)                # å°†Yè½´åæ ‡èµ‹å€¼ç»™Xè½´
            cube_tf.transform.translation.y = -float(point_x)               # å°†Xè½´åæ ‡èµ‹å€¼ç»™Yè½´
            cube_tf.transform.translation.z = -float(point_y)               # å°†Zè½´åæ ‡èµ‹å€¼ç»™Zè½´
            ori = tf_transformations.quaternion_from_euler(m_r+1.57, 0, 0)  # è®¡ç®—å§¿æ€çš„å››å…ƒæ•°
            cube_tf.transform.rotation.x = ori[0]
            cube_tf.transform.rotation.y = ori[1]
            cube_tf.transform.rotation.z = ori[2]
            cube_tf.transform.rotation.w = ori[3]
            msg = String()
            msg.data = str(ip)
            self.obj_pub.publish(msg)
            self.tf_pub.sendTransform(cube_tf)  # å‘å¸ƒTFå˜æ¢æ¶ˆæ¯
                

def main():
    rclpy.init()
    node = YoloDetection()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("Shutting down")
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
