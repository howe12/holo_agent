#!/usr/bin/env python3
import os
import sys
import rclpy
from rclpy.node import Node
from rclpy.logging import get_logger
from geometry_msgs.msg import TransformStamped
from std_msgs.msg import String
import time

import numpy as np
import tf2_ros
import tf_transformations
# from time import time

from std_msgs.msg import Header
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge,CvBridgeError

import cv2
from ultralytics import YOLO
from ament_index_python.packages import get_package_share_directory

class YoloDetection(Node):
# åˆå§‹åŒ–å‡½æ•°ï¼ŒåŒ…æ‹¬åŠ è½½æ¨¡å‹å’Œåˆ›å»ºè®¢é˜…è€…
    def __init__(self):
        # åˆå§‹åŒ–èŠ‚ç‚¹
        super().__init__('Yolo')
        self.logger = get_logger("yolov8") # åˆ›å»ºæ—¥å¿—è®°å½•å™¨

        # åˆå§‹åŒ–æ¨¡å‹ä¿¡æ¯
        ros2_yolov8 = get_package_share_directory('ros2_yolov8')  # åŠŸèƒ½åŒ…åœ°å€
        model_path = os.path.join(ros2_yolov8, 'config', 'best.pt')  # æ¨¡å‹è·¯å¾„
        self.model = YOLO(model_path) # åŠ è½½æ¨¡å‹

        # åˆå§‹åŒ–ç›¸æœºä¿¡æ¯
        self.sub_info = self.create_subscription(CameraInfo, '/camera/camera/color/camera_info', self.imageCameraInfoCallback, 10)    # ç›¸æœºä¿¡æ¯è¯é¢˜
        self.image_sub = self.create_subscription(Image, '/camera/camera/color/image_raw', self.detect, 10)  
        time.sleep(3)                         # rgbå›¾åƒè¯é¢˜
        self.depth_sub = self.create_subscription(Image, "/camera/camera/aligned_depth_to_color/image_raw", self.camera_depth_cb, 10) # æ·±åº¦å›¾åƒè¯é¢˜
        self.debug_pub = self.create_publisher(Image, "/debug_image", 1)    # æœ€ç»ˆå›¾åƒè¾“å‡ºè¯é¢˜
        self.camera_reference_frame = "camera_link"                         # å®šä¹‰æ‘„åƒå¤´åæ ‡ç³»
        self.tf_pub = tf2_ros.TransformBroadcaster(self)                    # ç‰©ä½“åæ ‡å˜æ¢å¹¿æ’­
        self.obj_pub = self.create_publisher(String, "/object_id", 10)
 
        # time.sleep(5)
        
        self.bridge = CvBridge()
        self.device = 'cpu'
        self.conf = 0.5  # è®¾ç½®æ¨¡å‹ç½®ä¿¡åº¦
        
        self.obj_id = [1,2,3,4]

        

    def imageCameraInfoCallback(self, msg):
        """
        è·å–ç›¸æœºå†…å‚ä¿¡æ¯
        """
        # è·å–å›¾åƒå°ºå¯¸
        self.image_width = msg.width
        self.image_height = msg.height
        # è·å–ç›¸æœºå†…å‚
        self.fx = msg.k[0]
        self.fy = msg.k[4]
        self.cx = msg.k[2]
        self.cy = msg.k[5]

    def predict(self, frame):
        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        results = self.model(frame, conf=self.conf,show_labels=False,show_conf=False,show_boxes=False)

        for result in results:
            # è¾“å‡ºç»“æœ
            # self.logger.info(f"ğŸ¯ ç»“æœclsä¸º: \n{result.obb.cls}")
            # # self.logger.info(f"ğŸ¯ ç¬¬äºŒä¸ªç‰©ä½“ä¸º: \n{result.obb.cls[1]}")
            # self.logger.info(f"ğŸ¯ ç»“æœsizeä¸º: \n{result.obb.cls.size(0)}")
            # self.logger.info(f"ğŸ¯ xywhrä¸º: \n{result.obb.xywhr}")
            # self.logger.info(f"ğŸ¯ ç»“æœxä¸º: \n{result.obb.xywhr[0,0]}")
            # self.logger.info(f"ğŸ¯ ç»“æœyä¸º: \n{result.obb.xywhr[0,1]}")
            # self.logger.info(f"ğŸ¯ ç»“æœxyxyxyxyä¸º: \n{result.obb.xyxyxyxy}")
            # # å·¦ä¸Šè§’åæ ‡
            # self.logger.info(f"ğŸ¯ ç»“æœx1ä¸º: \n{result.obb.xyxyxyxy[0,0]}")
            # # å³ä¸‹è§’åæ ‡
            # self.logger.info(f"ğŸ¯ ç»“æœx2ä¸º: \n{result.obb.xyxyxyxy[0,2]}")
            
            self.obb = result.obb



            # # è®¡ç®—ROIçš„è¾¹ç•Œ
            # x1, y1 = np.min(points, axis=0)  # å·¦ä¸Šè§’
            # x2, y2 = np.max(points, axis=0)  # å³ä¸‹è§’
            # roi = frame[y1:y2, x1:x2]

            # # åˆ›å»ºé»‘è‰²æ©ç 
            # mask = np.zeros_like(roi, dtype=np.uint8)
            # # åœ¨æ©ç ä¸Šç”»ä¸€ä¸ªç™½è‰²åœ†å½¢
            # cv2.circle(mask, (int(result.obb.xywhr[0,0]), int(result.obb.xywhr[0,1])), 10, (255, 255, 255), -1)
            # # ä½¿ç”¨ bitwise_and ä»…ä¿ç•™åœ†å½¢éƒ¨åˆ†
            # roi_circle = cv2.bitwise_and(roi, mask)


        return results

    def plot_boxes(self, results, frame):
        # è®¡ç®—å¸§ç‡å’Œç»˜åˆ¶è¾¹ç•Œæ¡†

        fps = 1000.0/ results[0].speed['inference']
        cv2.putText(frame, f'FPS: {int(fps)}', (20,50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)
        frame = results[0].plot()
        # # å°†ç‰©ä½“ä¸­å¿ƒç‚¹åœ¨å›¾ç‰‡ä¸Šæ˜¾ç¤ºå‡ºæ¥
        # cv2.circle(frame, (int(self.obb.xywhr[0,0]), int(self.obb.xywhr[0,1])), 3, (0, 255, 0), 5)
        # # æ·»åŠ ä¸€æ¡çº¿ï¼Œä»ç‰©ä½“ä¸­å¿ƒç‚¹ï¼Œæ–œç‡ä¸ºç‰©ä½“çš„è§’åº¦çš„çº¿
        
        # line_length = 30   # çº¿æ®µé•¿åº¦
        # angle = float(self.obb.xywhr[0, 4])  # çº¿æ®µè§’åº¦ï¼ˆå¼§åº¦ï¼‰

        # # è®¡ç®—ç»ˆç‚¹åæ ‡
        # end_x = int(int(self.obb.xywhr[0,0]) + line_length * np.cos(angle))
        # end_y = int(int(self.obb.xywhr[0,1]) + line_length * np.sin(angle))

        # cv2.line(frame, (int(self.obb.xywhr[0,0]), int(self.obb.xywhr[0,1])), (end_x, end_y), (0, 255, 0), 2)
        
        # cv2.imshow("frame",frame)
        # cv2.waitKey(1)

        return frame

    def detect(self, msg):
        self.color_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        results    = self.predict(self.color_image)
        frame      = self.plot_boxes(results, self.color_image)
        detect_img = self.bridge.cv2_to_imgmsg(frame, "bgr8")
        self.debug_pub.publish(detect_img)

    # æ·±åº¦å›¾åƒå›è°ƒå‡½æ•°
    def camera_depth_cb(self, msg):
        
        self.depth_image = self.bridge.imgmsg_to_cv2(msg, "32FC1")     # å°†ROSæ¶ˆæ¯è½¬æ¢ä¸ºOpenCVæ ¼å¼çš„æ·±åº¦å›¾åƒ
        depth_array = np.array(self.depth_image, dtype=np.float32)     # å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸ºNumPyæ•°ç»„
        cv2.normalize(depth_array, depth_array, 0, 1, cv2.NORM_MINMAX) # å°†æ·±åº¦å›¾åƒæ•°æ®å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        depth_8 = (depth_array * 255).round().astype(np.uint8)         # å°†å½’ä¸€åŒ–åçš„æ·±åº¦å›¾åƒè½¬æ¢ä¸º8ä½æ— ç¬¦å·æ•´æ•°
        cv_depth = np.zeros_like(self.color_image)                     # åˆ›å»ºä¸RGBå›¾åƒç›¸åŒå¤§å°çš„æ·±åº¦å›¾åƒ
        try:
            cv_depth[:, :, 0] = depth_8                                # å°†æ·±åº¦å›¾åƒæ•°æ®å¤åˆ¶åˆ°RGBå›¾åƒçš„æ¯ä¸ªé€šé“
            cv_depth[:, :, 1] = depth_8
            cv_depth[:, :, 2] = depth_8
        except:
            return   
         
        if len(self.obb) == None:
            return
        
        size = self.obb.cls.size(0)

        # ä¾¿åˆ©æ‰€æœ‰çš„ç‰©ä½“

        for i in range(size):
            # è·å–ç‰©ä½“çš„è¾¹ç•Œæ¡†åæ ‡
            m_x = int(self.obb.xywhr[i,0])
            m_y = int(self.obb.xywhr[i,1])
            m_w = int(self.obb.xywhr[i,2])
            m_h = int(self.obb.xywhr[i,3])
            m_r = self.obb.xywhr[i,4]
            ip  = int(self.obb.cls[i])
        
            """
            # è·å–åœ†å½¢ROIåŒºåŸŸ
            center = (m_x, m_y)  # åœ†å¿ƒä½ç½®
            radius = int(m_h/2)  # åœ†å½¢åŠå¾„ 
            mask = np.zeros_like(depth_array, dtype=np.float32)  # åˆ›å»ºä¸€ä¸ªå’ŒåŸå›¾å¤§å°ç›¸åŒçš„é»‘è‰²æ©ç å›¾åƒ
            cv2.circle(mask, center, radius, 255, -1)            # åœ¨æ©ç å›¾åƒä¸­ç»˜åˆ¶ä¸€ä¸ªç™½è‰²åœ†å½¢ï¼Œ-1 è¡¨ç¤ºå¡«å……åœ†å½¢            
            roi_circle = cv2.bitwise_and(depth_array, mask)      # æå–åœ†å½¢ROIåŒºåŸŸï¼Œé€šè¿‡æŒ‰ä½ä¸æ“ä½œ
            count = 0                                            # åˆå§‹åŒ–ç»Ÿè®¡æ·±åº¦æ¬¡æ•°
            sum_z = 0.0                                          # åˆå§‹åŒ–æ·±åº¦å€¼æ€»å’Œ
            # è®¡ç®—ROIåŒºåŸŸå†…æœ‰æ•ˆåƒç´ ç‚¹æ•°é‡å’Œæ·±åº¦å€¼æ€»å’Œ
            for i in range(0, roi_circle.shape[0]):
                for j in range(0, roi_circle.shape[1]):
                    value = roi_circle.item(i, j) / 1000.0
                    
                    if value > 0.05:
                        self.get_logger().info(f"ğŸ¯ ç¬¬{i,j}åƒç´ çš„value: {value}")
                        count += 1
                        sum_z += value
            if count == 0 or sum_z == 0:
                return 
            
            mean_z = sum_z / count # è®¡ç®—ROIåŒºåŸŸå†…å¹³å‡æ·±åº¦å€¼
            print(f"ROI åŒºåŸŸå†…çš„å¹³å‡æ·±åº¦å€¼: {mean_z} ç±³")
            cv2.imshow("Depth", depth_array)
            cv2.imshow("Mask", mask)
            cv2.imshow("Circular ROI", roi_circle)
            cv2.waitKey(1)
            """

            # è·å–çŸ©å½¢ROIåŒºåŸŸ
            obb_xyxyxyxy = self.obb.xyxyxyxy[0]  # å–å‡ºç¬¬ä¸€ä¸ªç›®æ ‡çš„ 8 ä¸ªåæ ‡å€¼      
            points = np.array(obb_xyxyxyxy.view(4, 2).numpy(), dtype=np.int32) # é‡æ–°æ•´ç†æˆ [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]
            left_top_x , left_top_y  = np.min(points, axis=0)  # å·¦ä¸Šè§’
            right_low_x, right_low_y = np.max(points, axis=0)  # å³ä¸‹è§’
            roi_depth = self.depth_image[left_top_y:right_low_y,left_top_x:right_low_x] # è·å–ROIåŒºåŸŸçš„æ·±åº¦å›¾åƒ
            count = 0                               # åˆå§‹åŒ–ç»Ÿè®¡æ·±åº¦æ¬¡æ•°
            sum_z = 0.0                             # åˆå§‹åŒ–æ·±åº¦å€¼æ€»å’Œ
            
            # è®¡ç®—ROIåŒºåŸŸå†…æœ‰æ•ˆåƒç´ ç‚¹æ•°é‡å’Œæ·±åº¦å€¼æ€»å’Œ
            for j in range(0, roi_depth.shape[0]):
                for k in range(0, roi_depth.shape[1]):
                    value = roi_depth.item(j, k) / 1000.0
                    if value > 0:
                        count += 1
                        sum_z += value
            if count == 0 or sum_z == 0:
                return 
            
            mean_z = sum_z / count # è®¡ç®—ROIåŒºåŸŸå†…å¹³å‡æ·±åº¦å€¼
            # self.get_logger().info(f"ğŸ¯ æ·±åº¦å€¼ä¸º: {mean_z}")
        
            # è®¡ç®—ç‰©ä½“åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ä¸‰ç»´åæ ‡
            x = (m_x - self.cx) / self.fx
            y = (m_y - self.cy) / self.fy
            point_x = mean_z * x
            point_y = mean_z * y
            point_z = mean_z

            # åˆ›å»ºTFå˜æ¢æ¶ˆæ¯å¹¶å‘å¸ƒ
            cube_tf = TransformStamped()
            cube_tf.header.stamp = self.get_clock().now().to_msg()
            cube_tf.header.frame_id = self.camera_reference_frame
            cube_tf.child_frame_id = "object_"+str(ip)
            cube_tf.transform.translation.x = float(point_z)                # å°†Yè½´åæ ‡èµ‹å€¼ç»™Xè½´
            cube_tf.transform.translation.y = -float(point_x)               # å°†Xè½´åæ ‡èµ‹å€¼ç»™Yè½´
            cube_tf.transform.translation.z = -float(point_y)               # å°†Zè½´åæ ‡èµ‹å€¼ç»™Zè½´
            ori = tf_transformations.quaternion_from_euler(m_r+1.57, 0, 0)  # è®¡ç®—å§¿æ€çš„å››å…ƒæ•°
            cube_tf.transform.rotation.x = ori[0]
            cube_tf.transform.rotation.y = ori[1]
            cube_tf.transform.rotation.z = ori[2]
            cube_tf.transform.rotation.w = ori[3]
            msg = String()
            msg.data = str(ip)
            self.obj_pub.publish(msg)
            self.tf_pub.sendTransform(cube_tf)  # å‘å¸ƒTFå˜æ¢æ¶ˆæ¯

            # # åˆå¹¶RGBå›¾åƒå’Œæ·±åº¦å›¾åƒï¼Œå¹¶å‘å¸ƒè°ƒè¯•ä¿¡æ¯
            # rgbd = np.concatenate((self.color_image, cv_depth), axis=1)
            # try:
            #     # faces_message = self.bridge.cv2_to_imgmsg(rgbd, "bgr8")
            #     # self.debug_pub.publish(faces_message)
            #     pass
            # except CvBridgeError as e:
            #     print(e)

            
        
     

def main():
    rclpy.init()
    node = YoloDetection()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("Shutting down")
    node.destroy_node()
    rclpy.shutdown()
    # cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
